{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1928924a-e18d-402f-99c5-6303f4a3d9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score,cohen_kappa_score, matthews_corrcoef\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pd.options.mode.chained_assignment = None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c98ae8cd-f904-4847-9f58-2211baf452ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_data_split(raw_data, train_mapping, test_mapping):\n",
    "    train_data = pd.DataFrame(columns=raw_data.columns)\n",
    "    test_data = pd.DataFrame(columns=raw_data.columns)\n",
    "    \n",
    "    for case_id in raw_data.index:\n",
    "        case_general_id = case_id[0:20]\n",
    "        if case_general_id in train_mapping.values[:,1]:\n",
    "            train_data.loc[case_id]= raw_data.loc[case_id, :]\n",
    "        elif case_general_id in test_mapping.values[:,1]:\n",
    "            test_data.loc[case_id]= raw_data.loc[case_id, :]\n",
    "            \n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4313c64b-67ff-4fd2-896c-5035fc16e6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def equalize_mapping(mapping):\n",
    "    is_HGG =  mapping['Grade']=='HGG'\n",
    "    is_LGG =  mapping['Grade']=='LGG'\n",
    "    hggs = mapping[is_HGG]\n",
    "    lggs = mapping[is_LGG]\n",
    "    hggs = hggs.sample(n=len(lggs))\n",
    "    equalized_mapping = pd.concat([hggs, lggs])\n",
    "    return equalized_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d1148d6-1902-4c56-81e3-f69c2519a14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def equalize_dataset(mapping, dataset):\n",
    "    mapping_ids = mapping[\"ID\"].tolist()\n",
    "    dataset.index = dataset.index.astype('str')\n",
    "    equalized_train_dataset = pd.DataFrame()\n",
    "    for id in mapping_ids:   \n",
    "        case_df = dataset[dataset.index.str.contains(id)]\n",
    "        equalized_train_dataset = pd.concat([equalized_train_dataset, case_df])\n",
    "    return equalized_train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "670886fb-e46a-4477-baf9-ca78ac96c3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_modalities(input_data):\n",
    "    \n",
    "    flair= pd.DataFrame(columns=input_data.columns)\n",
    "    t1c = pd.DataFrame(columns=input_data.columns)\n",
    "    t1= pd.DataFrame(columns=input_data.columns)\n",
    "    t2 = pd.DataFrame(columns=input_data.columns)\n",
    "    \n",
    "    for case_id in input_data.index:\n",
    "        if \"FLAIR\" in case_id:\n",
    "            flair.loc[case_id]= input_data.loc[case_id, :]\n",
    "        elif \"T1C\" in case_id:\n",
    "            t1c.loc[case_id]= input_data.loc[case_id, :]\n",
    "        elif \"T1\" in case_id:\n",
    "            t1.loc[case_id]= input_data.loc[case_id, :]\n",
    "        elif \"T2\" in case_id:\n",
    "            t2.loc[case_id]= input_data.loc[case_id, :]\n",
    "            \n",
    "            \n",
    "    labels = (flair.loc[:, 'Grade']).to_numpy()\n",
    "    \n",
    "    flair.drop('Grade',axis='columns', inplace=True)\n",
    "    t1c.drop('Grade',axis='columns', inplace=True)\n",
    "    t1.drop('Grade',axis='columns', inplace=True)\n",
    "    t2.drop('Grade',axis='columns', inplace=True)\n",
    "    \n",
    "    return flair, t1c, t1, t2, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04075c61-a040-4660-94e3-d41674c48784",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_features(dataset, number_of_features):\n",
    "    X = dataset.loc[:, dataset.columns != \"Grade\"]\n",
    "    y = dataset.loc[:, \"Grade\"]\n",
    "    \n",
    "    standard_scaler = StandardScaler().fit(X)\n",
    "    X[X.columns] = standard_scaler.fit_transform(X[X.columns])\n",
    "    \n",
    "    select_k_best = SelectKBest(f_classif).fit(X, Y)\n",
    "    \n",
    "    scored_features = pd.DataFrame({'Feature':list(X.columns), 'Score':select_k_best.scores_})\n",
    "    scored_features.sort_values(by='Score', ascending=False, inplace=True)\n",
    "    scored_features.to_csv(\"output/scored_features.csv\")\n",
    "    \n",
    "    best_features = scored_features.nlargest(number_of_features,'Score')\n",
    "    best_features = best_features.loc[:, \"Feature\"]\n",
    "    # print(\"Selected features: \")\n",
    "    # print(best_features)\n",
    "    best_features.to_csv(\"output/best_features.csv\")\n",
    "\n",
    "    selected_features = X.loc[dataset.index, best_features]\n",
    "    selected_features[\"Grade\"] = Y\n",
    "    \n",
    "    return selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5db408e-c239-4abe-b557-7353be6680bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_majority_proba(proba_arr):\n",
    "    \n",
    "    hgg_proba = 0\n",
    "    lgg_proba = 0\n",
    "    \n",
    "    for modality_proba in proba_arr:\n",
    "        hgg_proba += modality_proba[0]\n",
    "        lgg_proba += modality_proba[1]\n",
    "        \n",
    "    if  hgg_proba >= lgg_proba:\n",
    "        return \"HGG\"\n",
    "    else:\n",
    "        return \"LGG\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c53569c4-46fe-48ef-a214-8c3064ec0907",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_scaler(dataset):\n",
    "    dataset_values = dataset.loc[:, dataset.columns != \"Grade\"]\n",
    "    standard_scaler = StandardScaler().fit(dataset_values)\n",
    "    return standard_scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34df01ec-6a1d-44f5-8a61-6b372f40bedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_pca(dataset, scaler):\n",
    "    dataset_values = dataset.loc[:, dataset.columns != \"Grade\"]\n",
    "    dataset_labels = dataset.loc[:, \"Grade\"]\n",
    "    dataset_index = dataset.index\n",
    "\n",
    "    dataset_values[dataset_values.columns] = scaler.transform(dataset_values[dataset_values.columns])\n",
    "    \n",
    "    pca = PCA(.95)\n",
    "    \n",
    "    pca.fit(dataset_values)\n",
    "    \n",
    "    dataset_values = pca.transform(dataset_values)\n",
    "    \n",
    "    dataset_pca = pd.DataFrame(dataset_values, index=dataset_index)\n",
    "    dataset_pca[\"Grade\"] = dataset_labels\n",
    "    \n",
    "    return dataset_pca, pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9d1645a-87ad-4122-89b3-7bae9c5b2db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_dataset(dataset, scaler, pca):\n",
    "    dataset_values = dataset.loc[:, dataset.columns != \"Grade\"]\n",
    "    dataset_labels = dataset.loc[:, \"Grade\"]\n",
    "    dataset_index = dataset.index\n",
    "\n",
    "    dataset_values[dataset_values.columns] = scaler.transform(dataset_values[dataset_values.columns])\n",
    "    \n",
    "    dataset_values = pca.transform(dataset_values)\n",
    "    \n",
    "    preprocessed_dataset = pd.DataFrame(dataset_values, index=dataset_index)\n",
    "    preprocessed_dataset[\"Grade\"] = dataset_labels\n",
    "    \n",
    "    return preprocessed_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c18f3982-cf50-4838-8829-909f355918f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train labels distribution: Counter({'HGG': 233, 'LGG': 61})\n",
      "Test labels distribution: Counter({'HGG': 59, 'LGG': 15})\n",
      "\n",
      "\n",
      "[[57  2]\n",
      " [ 8  7]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         HGG       0.88      0.97      0.92        59\n",
      "         LGG       0.78      0.47      0.58        15\n",
      "\n",
      "    accuracy                           0.86        74\n",
      "   macro avg       0.83      0.72      0.75        74\n",
      "weighted avg       0.86      0.86      0.85        74\n",
      "\n",
      "Accuracy: 0.86486\n",
      "Cohen's Kappa: 0.50863\n",
      "MCC: 0.53229\n",
      "Train labels distribution: Counter({'HGG': 233, 'LGG': 61})\n",
      "Test labels distribution: Counter({'HGG': 59, 'LGG': 15})\n",
      "\n",
      "\n",
      "[[58  1]\n",
      " [ 8  7]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         HGG       0.88      0.98      0.93        59\n",
      "         LGG       0.88      0.47      0.61        15\n",
      "\n",
      "    accuracy                           0.88        74\n",
      "   macro avg       0.88      0.72      0.77        74\n",
      "weighted avg       0.88      0.88      0.86        74\n",
      "\n",
      "Accuracy: 0.87838\n",
      "Cohen's Kappa: 0.54446\n",
      "MCC: 0.58223\n",
      "Train labels distribution: Counter({'HGG': 234, 'LGG': 60})\n",
      "Test labels distribution: Counter({'HGG': 58, 'LGG': 16})\n",
      "\n",
      "\n",
      "[[33 25]\n",
      " [ 3 13]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         HGG       0.92      0.57      0.70        58\n",
      "         LGG       0.34      0.81      0.48        16\n",
      "\n",
      "    accuracy                           0.62        74\n",
      "   macro avg       0.63      0.69      0.59        74\n",
      "weighted avg       0.79      0.62      0.65        74\n",
      "\n",
      "Accuracy: 0.62162\n",
      "Cohen's Kappa: 0.25468\n",
      "MCC: 0.31419\n",
      "Train labels distribution: Counter({'HGG': 234, 'LGG': 61})\n",
      "Test labels distribution: Counter({'HGG': 58, 'LGG': 15})\n",
      "\n",
      "\n",
      "[[28 30]\n",
      " [ 4 11]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         HGG       0.88      0.48      0.62        58\n",
      "         LGG       0.27      0.73      0.39        15\n",
      "\n",
      "    accuracy                           0.53        73\n",
      "   macro avg       0.57      0.61      0.51        73\n",
      "weighted avg       0.75      0.53      0.58        73\n",
      "\n",
      "Accuracy: 0.53425\n",
      "Cohen's Kappa: 0.13156\n",
      "MCC: 0.17597\n",
      "Train labels distribution: Counter({'HGG': 234, 'LGG': 61})\n",
      "Test labels distribution: Counter({'HGG': 58, 'LGG': 15})\n",
      "\n",
      "\n",
      "[[17 41]\n",
      " [ 1 14]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         HGG       0.94      0.29      0.45        58\n",
      "         LGG       0.25      0.93      0.40        15\n",
      "\n",
      "    accuracy                           0.42        73\n",
      "   macro avg       0.60      0.61      0.42        73\n",
      "weighted avg       0.80      0.42      0.44        73\n",
      "\n",
      "Accuracy: 0.42466\n",
      "Cohen's Kappa: 0.11387\n",
      "MCC: 0.21227\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"output/features.csv\", index_col=0)\n",
    "name_mapping = pd.read_csv(\"mapping/name_mapping.csv\")\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "\n",
    "X = name_mapping.values[:,1]\n",
    "y = name_mapping.values[:,0]\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "     \n",
    "    X_train, X_test = X[train_index], X[test_index] \n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "    print(\"Train labels distribution:\", Counter(y_train))\n",
    "    print(\"Test labels distribution:\",Counter(y_test))\n",
    "    print(\"\\n\")\n",
    "\n",
    "    train_mapping = pd.DataFrame({'Grade': y_train, 'ID': X_train})    \n",
    "    test_mapping = pd.DataFrame({'Grade': y_test, 'ID': X_test})\n",
    "    equalized_train_mapping = equalize_mapping(train_mapping)\n",
    "        \n",
    "    (train_dataset, test_dataset) = train_test_data_split(dataset, train_mapping, test_mapping)\n",
    "    \n",
    "    scaler = prepare_scaler(train_dataset)\n",
    "    \n",
    "    pca_train_dataset, pca = apply_pca(train_dataset, scaler)\n",
    "    \n",
    "    equalized_train_dataset = equalize_dataset(equalized_train_mapping, pca_train_dataset)\n",
    "    \n",
    "    (flair_data, t1c_data, t1_data, t2_data, labels) = split_modalities(equalized_train_dataset)\n",
    "    \n",
    "    flair_classifier = RandomForestClassifier()\n",
    "    t1c_classifier = RandomForestClassifier()\n",
    "    t1_classifier = RandomForestClassifier()\n",
    "    t2_classifier = RandomForestClassifier()\n",
    "    \n",
    "    flair_classifier.fit(flair_data.to_numpy(), labels)\n",
    "    t1c_classifier.fit(t1c_data.to_numpy(), labels)\n",
    "    t1_classifier.fit(t1_data.to_numpy(), labels)\n",
    "    t2_classifier.fit(t2_data.to_numpy(), labels)\n",
    "    \n",
    "    preprocessed_test_dataset = preprocess_dataset(test_dataset, scaler, pca)\n",
    "    \n",
    "    (test_flair_data, test_t1c_data, test_t1_data, test_t2_data, test_labels) = split_modalities(preprocessed_test_dataset)\n",
    "    \n",
    "    number_of_test_cases = len(test_mapping)\n",
    "    \n",
    "    test_results = []\n",
    "\n",
    "    for i in range(number_of_test_cases):\n",
    "        probability_array = []\n",
    "\n",
    "        flair_result = flair_classifier.predict_proba(test_flair_data.iloc[i].to_numpy().reshape(1,-1))[0]\n",
    "        probability_array.append(flair_result)\n",
    "            \n",
    "        t1c_result = t1c_classifier.predict_proba(test_t1c_data.iloc[i].to_numpy().reshape(1,-1))[0]\n",
    "        probability_array.append(t1c_result)\n",
    "            \n",
    "        t1_result = t1_classifier.predict_proba(test_t1_data.iloc[i].to_numpy().reshape(1,-1))[0]\n",
    "        probability_array.append(t1_result)\n",
    "            \n",
    "        t2_result = t2_classifier.predict_proba(test_t2_data.iloc[i].to_numpy().reshape(1,-1))[0]\n",
    "        probability_array.append(t2_result)\n",
    "                \n",
    "        final_prediction = check_majority_proba(probability_array)\n",
    "\n",
    "        test_results.append(final_prediction)\n",
    "        \n",
    "    test_results = np.array(test_results)\n",
    "    \n",
    "    print(confusion_matrix(test_labels, test_results))\n",
    "    print(classification_report(test_labels, test_results))\n",
    "    \n",
    "    acc = accuracy_score(test_labels, test_results)\n",
    "    kappa = cohen_kappa_score(test_labels, test_results)\n",
    "    mcc = matthews_corrcoef(test_labels, test_results)\n",
    "    \n",
    "    print(\"Accuracy: {:.5f}\".format(acc))\n",
    "    print(\"Cohen's Kappa: {:.5f}\".format(kappa))\n",
    "    print(\"MCC: {:.5f}\".format(mcc))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1920fe59-94b8-43a2-8adb-9aae4a93ec9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
