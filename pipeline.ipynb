{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "eb035585-3b7a-4db3-8f98-0fc2be8221ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score,cohen_kappa_score, matthews_corrcoef, precision_score, recall_score, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.decomposition import PCA\n",
    "from matplotlib import rcParams\n",
    "\n",
    "pd.options.mode.chained_assignment = None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1f548fbf-1e52-43aa-a463-982d0daaacaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_data_split(raw_data, train_mapping, test_mapping):\n",
    "    train_data = pd.DataFrame(columns=raw_data.columns)\n",
    "    test_data = pd.DataFrame(columns=raw_data.columns)\n",
    "    \n",
    "    for case_id in raw_data.index:\n",
    "        case_general_id = case_id[0:20]\n",
    "        if case_general_id in train_mapping.values[:,1]:\n",
    "            train_data.loc[case_id]= raw_data.loc[case_id, :]\n",
    "        elif case_general_id in test_mapping.values[:,1]:\n",
    "            test_data.loc[case_id]= raw_data.loc[case_id, :]\n",
    "            \n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a203da11-d69e-43be-b5c9-04ce726ad319",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_modalities(input_data):\n",
    "    \n",
    "    flair= pd.DataFrame(columns=input_data.columns)\n",
    "    t1c = pd.DataFrame(columns=input_data.columns)\n",
    "    t1= pd.DataFrame(columns=input_data.columns)\n",
    "    t2 = pd.DataFrame(columns=input_data.columns)\n",
    "    \n",
    "    for case_id in input_data.index:\n",
    "        if \"FLAIR\" in case_id:\n",
    "            flair.loc[case_id]= input_data.loc[case_id, :]\n",
    "        elif \"T1C\" in case_id:\n",
    "            t1c.loc[case_id]= input_data.loc[case_id, :]\n",
    "        elif \"T1\" in case_id:\n",
    "            t1.loc[case_id]= input_data.loc[case_id, :]\n",
    "        elif \"T2\" in case_id:\n",
    "            t2.loc[case_id]= input_data.loc[case_id, :]\n",
    "            \n",
    "            \n",
    "    labels = (flair.loc[:, 'Grade']).to_numpy()\n",
    "   \n",
    "    flair.drop('Grade',axis='columns', inplace=True)\n",
    "    t1c.drop('Grade',axis='columns', inplace=True)\n",
    "    t1.drop('Grade',axis='columns', inplace=True)\n",
    "    t2.drop('Grade',axis='columns', inplace=True)\n",
    "    \n",
    "    return flair, t1c, t1, t2, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "15737baf-eacf-401a-a916-a3fdd1dad7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_scaler(dataset):\n",
    "    dataset_values = dataset.loc[:, dataset.columns != \"Grade\"]\n",
    "    standard_scaler = StandardScaler().fit(dataset_values)\n",
    "    return standard_scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "28386ca7-bac8-49d0-8ef9-6c2086df1cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_pca(dataset, scaler):\n",
    "    dataset_values = dataset.loc[:, dataset.columns != \"Grade\"]\n",
    "    dataset_labels = dataset.loc[:, \"Grade\"]\n",
    "    dataset_index = dataset.index\n",
    "        \n",
    "    dataset_values[dataset_values.columns] = scaler.transform(dataset_values[dataset_values.columns])\n",
    "        \n",
    "    pca = PCA(.95)\n",
    "    \n",
    "    pca.fit(dataset_values)\n",
    "        \n",
    "    dataset_values = pca.transform(dataset_values)\n",
    "    \n",
    "    dataset_pca = pd.DataFrame(dataset_values, index=dataset_index)\n",
    "    dataset_pca[\"Grade\"] = dataset_labels\n",
    "    \n",
    "    return dataset_pca, pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cd69a58c-f72f-4fb2-b271-d8c344bbcf75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def equalize_mapping(mapping):\n",
    "    is_HGG =  mapping['Grade']=='HGG'\n",
    "    is_LGG =  mapping['Grade']=='LGG'\n",
    "    hggs = mapping[is_HGG]\n",
    "    lggs = mapping[is_LGG]\n",
    "    \n",
    "    x = len(lggs)\n",
    "    hggs = hggs.sample(n=x)\n",
    "    equalized_mapping = pd.concat([hggs, lggs])\n",
    "    return equalized_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b1cc0883-b3f3-4a85-a063-da2a1c4c469d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def equalize_dataset(mapping, dataset):\n",
    "    mapping_ids = mapping[\"ID\"].tolist()\n",
    "    dataset.index = dataset.index.astype('str')\n",
    "    equalized_train_dataset = pd.DataFrame()\n",
    "    for id in mapping_ids:   \n",
    "        case_df = dataset[dataset.index.str.contains(id)]\n",
    "        equalized_train_dataset = pd.concat([equalized_train_dataset, case_df])\n",
    "    return equalized_train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "925f868a-8996-4ea2-ba02-a89e95c15919",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_test_dataset(dataset, scaler, pca):\n",
    "    dataset_values = dataset.loc[:, dataset.columns != \"Grade\"]\n",
    "    dataset_labels = dataset.loc[:, \"Grade\"]\n",
    "    dataset_index = dataset.index\n",
    "    \n",
    "    dataset_values[dataset_values.columns] = scaler.transform(dataset_values[dataset_values.columns])\n",
    "        \n",
    "    dataset_values = pca.transform(dataset_values)\n",
    "    \n",
    "    preprocessed_dataset = pd.DataFrame(dataset_values, index=dataset_index)\n",
    "    preprocessed_dataset[\"Grade\"] = dataset_labels\n",
    "    \n",
    "    return preprocessed_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "29f5c6c8-21ce-42e4-8132-b1662dce41c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_majority_proba(proba_arr):\n",
    "    \n",
    "    hgg_proba = 0\n",
    "    lgg_proba = 0\n",
    "    \n",
    "    for modality_proba in proba_arr:\n",
    "        hgg_proba += modality_proba[0]\n",
    "        lgg_proba += modality_proba[1]\n",
    "        \n",
    "    if  hgg_proba >= lgg_proba:\n",
    "        return \"HGG\"\n",
    "    else:\n",
    "        return \"LGG\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e19c2dde-0426-4aab-ac34-ee295e4b5746",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_metrics(overall_acc, overall_kappa, overall_mcc, overall_precision, overall_recall, overall_dice, overall_hausdorff, overall_volume): \n",
    "    general_accuracy = pd.DataFrame({'Accuracy': overall_acc})\n",
    "    general_kappa = pd.DataFrame({'Kappa': overall_kappa})\n",
    "    general_mcc = pd.DataFrame({'MCC': overall_mcc})\n",
    "    general_precision = pd.DataFrame({'Precision': overall_precision})\n",
    "    general_recall = pd.DataFrame({'Recall': overall_recall})\n",
    "    general_dice = pd.DataFrame({'Dice': overall_dice})\n",
    "    general_hausdorff = pd.DataFrame({'Hausdorff': overall_hausdorff})\n",
    "    general_volume = pd.DataFrame({'Volume': overall_volume})\n",
    "        \n",
    "    accuracy_mean = float(general_accuracy.mean())\n",
    "    accuracy_median = float(general_accuracy.median())\n",
    "    accuracy_Q1 = general_accuracy.Accuracy.quantile([0.25]).to_numpy()[0]\n",
    "    accuracy_Q3 = general_accuracy.Accuracy.quantile([0.75]).to_numpy()[0]\n",
    "    accuracy_IQR = accuracy_Q3 - accuracy_Q1\n",
    "    kappa_mean = float(general_kappa.mean())\n",
    "    kappa_median = float(general_kappa.median())\n",
    "    kappa_Q1 = general_kappa.Kappa.quantile([0.25]).to_numpy()[0]\n",
    "    kappa_Q3 = general_kappa.Kappa.quantile([0.75]).to_numpy()[0]\n",
    "    kappa_IQR = kappa_Q3 - kappa_Q1\n",
    "    mcc_mean = float(general_mcc.mean())\n",
    "    mcc_median = float(general_mcc.median())\n",
    "    mcc_Q1 = general_mcc.MCC.quantile([0.25]).to_numpy()[0]\n",
    "    mcc_Q3 = general_mcc.MCC.quantile([0.75]).to_numpy()[0]\n",
    "    mcc_IQR = mcc_Q3 - mcc_Q1\n",
    "    precision_mean = float(general_precision.mean())\n",
    "    precision_median = float(general_precision.median())\n",
    "    precision_Q1 = general_precision.Precision.quantile([0.25]).to_numpy()[0]\n",
    "    precision_Q3 = general_precision.Precision.quantile([0.75]).to_numpy()[0]\n",
    "    precision_IQR = precision_Q3 - precision_Q1\n",
    "    recall_mean = float(general_recall.mean())\n",
    "    recall_median = float(general_recall.median())\n",
    "    recall_Q1 = general_recall.Recall.quantile([0.25]).to_numpy()[0]\n",
    "    recall_Q3 = general_recall.Recall.quantile([0.75]).to_numpy()[0]\n",
    "    recall_IQR = recall_Q3 - recall_Q1\n",
    "    dice_mean = float(general_dice.mean())\n",
    "    dice_median = float(general_dice.median())\n",
    "    dice_Q1 = general_dice.Dice.quantile([0.25]).to_numpy()[0]\n",
    "    dice_Q3 = general_dice.Dice.quantile([0.75]).to_numpy()[0]\n",
    "    dice_IQR = dice_Q3 - dice_Q1\n",
    "    hausdorff_mean = float(general_hausdorff.mean())\n",
    "    hausdorff_median = float(general_hausdorff.median())\n",
    "    hausdorff_Q1 = general_hausdorff.Hausdorff.quantile([0.25]).to_numpy()[0]\n",
    "    hausdorff_Q3 = general_hausdorff.Hausdorff.quantile([0.75]).to_numpy()[0]\n",
    "    hausdorff_IQR = hausdorff_Q3 - hausdorff_Q1\n",
    "    voulme_mean = float(general_volume.mean())\n",
    "    volume_median = float(general_volume.median())\n",
    "    volume_Q1 = general_volume.Volume.quantile([0.25]).to_numpy()[0]\n",
    "    volume_Q3 = general_volume.Volume.quantile([0.75]).to_numpy()[0]\n",
    "    volume_IQR = 0 \n",
    "    \n",
    "    accuracy_list = [accuracy_mean, accuracy_median, accuracy_Q1, accuracy_Q3, accuracy_IQR]\n",
    "    kappa_list = [kappa_mean, kappa_median, kappa_Q1, kappa_Q3, kappa_IQR]\n",
    "    mcc_list = [mcc_mean, mcc_median, mcc_Q1, mcc_Q3, mcc_IQR]\n",
    "    precision_list = [precision_mean, precision_median, precision_Q1, precision_Q3, precision_IQR]\n",
    "    recall_list = [recall_mean, recall_median, recall_Q1, recall_Q3, recall_IQR]\n",
    "    dice_list = [dice_mean, dice_median, dice_Q1, dice_Q3, dice_IQR]\n",
    "    hausdorff_list = [hausdorff_mean, hausdorff_median, hausdorff_Q1, hausdorff_Q3, hausdorff_IQR]\n",
    "    volume_list = [voulme_mean, volume_median, volume_Q1, volume_Q3, volume_IQR]\n",
    "\n",
    "    rows_labels = [\"Mean\", \"Median\", \"Q1\", \"Q3\", \"IQR\"]\n",
    "    column_labels = [\"Accuracy\", \"Kappa\", \"MCC\", \"Precision\",\"Recall\", \"Dice\", \"Hausdorff\", \"Volume\"]\n",
    "    metrics = pd.DataFrame(index=rows_labels, columns=column_labels)\n",
    "\n",
    "    metrics[\"Accuracy\"] = accuracy_list\n",
    "    metrics[\"Kappa\"] = kappa_list\n",
    "    metrics[\"MCC\"] = mcc_list\n",
    "    metrics[\"Precision\"] = precision_list\n",
    "    metrics[\"Recall\"] = recall_list\n",
    "    metrics[\"Dice\"] = dice_list\n",
    "    metrics[\"Hausdorff\"] = hausdorff_list\n",
    "    metrics[\"Volume\"] = volume_list\n",
    "\n",
    "    rounded_metrics = metrics.round(3)\n",
    "    rounded_metrics.to_csv(\"general_metrics.csv\")\n",
    "    \n",
    "    return rounded_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3585251d-6f33-4871-846d-3472b9f78d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "FOLD NUMBER:  1\n",
      "\n",
      "\n",
      "[[59  0]\n",
      " [ 2 13]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         HGG       0.97      1.00      0.98        59\n",
      "         LGG       1.00      0.87      0.93        15\n",
      "\n",
      "    accuracy                           0.97        74\n",
      "   macro avg       0.98      0.93      0.96        74\n",
      "weighted avg       0.97      0.97      0.97        74\n",
      "\n",
      "\n",
      "\n",
      "FOLD NUMBER:  2\n",
      "\n",
      "\n",
      "[[52  7]\n",
      " [ 7  8]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         HGG       0.88      0.88      0.88        59\n",
      "         LGG       0.53      0.53      0.53        15\n",
      "\n",
      "    accuracy                           0.81        74\n",
      "   macro avg       0.71      0.71      0.71        74\n",
      "weighted avg       0.81      0.81      0.81        74\n",
      "\n",
      "\n",
      "\n",
      "FOLD NUMBER:  3\n",
      "\n",
      "\n",
      "[[43 15]\n",
      " [ 3 13]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         HGG       0.93      0.74      0.83        58\n",
      "         LGG       0.46      0.81      0.59        16\n",
      "\n",
      "    accuracy                           0.76        74\n",
      "   macro avg       0.70      0.78      0.71        74\n",
      "weighted avg       0.83      0.76      0.78        74\n",
      "\n",
      "\n",
      "\n",
      "FOLD NUMBER:  4\n",
      "\n",
      "\n",
      "[[33 25]\n",
      " [ 2 13]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         HGG       0.94      0.57      0.71        58\n",
      "         LGG       0.34      0.87      0.49        15\n",
      "\n",
      "    accuracy                           0.63        73\n",
      "   macro avg       0.64      0.72      0.60        73\n",
      "weighted avg       0.82      0.63      0.66        73\n",
      "\n",
      "\n",
      "\n",
      "FOLD NUMBER:  5\n",
      "\n",
      "\n",
      "[[11 47]\n",
      " [ 1 14]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         HGG       0.92      0.19      0.31        58\n",
      "         LGG       0.23      0.93      0.37        15\n",
      "\n",
      "    accuracy                           0.34        73\n",
      "   macro avg       0.57      0.56      0.34        73\n",
      "weighted avg       0.78      0.34      0.33        73\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# dataset = pd.read_csv(\"output/2D_mask_features.csv\", index_col=0)\n",
    "# dataset = pd.read_csv(\"output/3D_mask_features.csv\", index_col=0)\n",
    "# dataset = pd.read_csv(\"output/ENS_mask_features.csv\", index_col=0)\n",
    "dataset = pd.read_csv(\"output/GT_mask_features.csv\", index_col=0)\n",
    "\n",
    "name_mapping = pd.read_csv(\"mapping/name_mapping.csv\")\n",
    "\n",
    "fold_iterator = 1\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "\n",
    "y = name_mapping.values[:,0]\n",
    "X = name_mapping.values[:,1]\n",
    "strat_label = name_mapping.values[:,8]\n",
    "\n",
    "dice = name_mapping.values[:,2]\n",
    "hausdorff = name_mapping.values[:,3]\n",
    "volume = name_mapping.values[:, 9]\n",
    "\n",
    "overall_acc = []\n",
    "overall_kappa = []\n",
    "overall_mcc = []\n",
    "overall_prc = []\n",
    "overall_rec = []\n",
    "overall_dice = []\n",
    "overall_hausdorff = []\n",
    "overall_volume = []\n",
    "\n",
    "column_labels = [\"Fold\", \"Accuracy\", \"Kappa\", \"MCC\", \"Precision\", \"Recall\", \"Dice\", \"Hausdorff\", \"Volume\"]\n",
    "fold_metrics = pd.DataFrame(columns=column_labels)\n",
    "\n",
    "columns_dc = [\"ID\", \"GT\", \"PRED\"]\n",
    "detailed_classification = pd.DataFrame(columns = columns_dc)\n",
    "\n",
    "\n",
    "for train_index, test_index in skf.split(X, strat_label):\n",
    "    print(\"\\n\")\n",
    "    print(\"FOLD NUMBER: \", fold_iterator)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    scaler = None\n",
    "    pca = None\n",
    "\n",
    "    X_train, X_test = X[train_index], X[test_index] \n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    strat_label_train, strat_label_test = strat_label[train_index], strat_label[test_index]\n",
    "    \n",
    "    dice_train, dice_test = dice[train_index], dice[test_index]\n",
    "    hausdorff_train, hausdorff_test = hausdorff[train_index], hausdorff[test_index]\n",
    "    volume_train, volume_test =  volume[train_index], volume[test_index]\n",
    "    \n",
    "    train_mapping = pd.DataFrame({'Grade': y_train, 'ID': X_train, 'Strat_Label': strat_label_train , 'Dice': dice_train, 'Hausdorff': hausdorff_train, 'Volume': volume_train})   \n",
    "    test_mapping = pd.DataFrame({'Grade': y_test, 'ID': X_test, 'Strat_Label': strat_label_test, 'Dice': dice_test, 'Hausdorff': hausdorff_test, 'Volume': volume_test})\n",
    "\n",
    "    equalized_train_mapping = equalize_mapping(train_mapping)\n",
    "\n",
    "    (train_dataset, test_dataset) = train_test_data_split(dataset, train_mapping, test_mapping)\n",
    "\n",
    "    scaler = prepare_scaler(train_dataset)\n",
    "\n",
    "    pca_train_dataset, pca = apply_pca(train_dataset, scaler)\n",
    "\n",
    "    equalized_train_dataset = equalize_dataset(equalized_train_mapping, pca_train_dataset)\n",
    "    \n",
    "    (flair_data, t1c_data, t1_data, t2_data, labels) = split_modalities(equalized_train_dataset)\n",
    "    \n",
    "    # flair_classifier = LogisticRegression()\n",
    "    # t1c_classifier = LogisticRegression()\n",
    "    # t1_classifier = LogisticRegression()\n",
    "    # t2_classifier = LogisticRegression()\n",
    "\n",
    "    # flair_classifier = KNeighborsClassifier()\n",
    "    # t1c_classifier = KNeighborsClassifier()\n",
    "    # t1_classifier = KNeighborsClassifier()\n",
    "    # t2_classifier = KNeighborsClassifier()\n",
    "    \n",
    "    # flair_classifier = DecisionTreeClassifier()\n",
    "    # t1c_classifier = DecisionTreeClassifier()\n",
    "    # t1_classifier = DecisionTreeClassifier()\n",
    "    # t2_classifier = DecisionTreeClassifier()\n",
    "    \n",
    "    # flair_classifier = SVC(gamma='auto', probability=True)\n",
    "    # t1c_classifier = SVC(gamma='auto', probability=True)\n",
    "    # t1_classifier = SVC(gamma='auto', probability=True)\n",
    "    # t2_classifier = SVC(gamma='auto', probability=True)\n",
    "    \n",
    "    # flair_classifier = RandomForestClassifier()\n",
    "    # t1c_classifier = RandomForestClassifier()\n",
    "    # t1_classifier = RandomForestClassifier()\n",
    "    # t2_classifier = RandomForestClassifier()\n",
    "    \n",
    "    flair_classifier = ExtraTreesClassifier()\n",
    "    t1c_classifier = ExtraTreesClassifier()\n",
    "    t1_classifier = ExtraTreesClassifier()\n",
    "    t2_classifier = ExtraTreesClassifier()\n",
    "    \n",
    "    flair_classifier.fit(flair_data.to_numpy(), labels)\n",
    "    t1c_classifier.fit(t1c_data.to_numpy(), labels)\n",
    "    t1_classifier.fit(t1_data.to_numpy(), labels)\n",
    "    t2_classifier.fit(t2_data.to_numpy(), labels)\n",
    "\n",
    "    preprocessed_test_dataset = preprocess_test_dataset(test_dataset, scaler, pca)\n",
    "\n",
    "    (test_flair_data, test_t1c_data, test_t1_data, test_t2_data, test_labels) = split_modalities(preprocessed_test_dataset)\n",
    "    \n",
    "    number_of_test_cases = len(test_mapping)\n",
    "\n",
    "    test_results = []\n",
    "\n",
    "    for i in range(number_of_test_cases):\n",
    "        probability_array = []\n",
    "\n",
    "        flair_result = flair_classifier.predict_proba(test_flair_data.iloc[i].to_numpy().reshape(1,-1))[0]\n",
    "        probability_array.append(flair_result)\n",
    "\n",
    "        t1c_result = t1c_classifier.predict_proba(test_t1c_data.iloc[i].to_numpy().reshape(1,-1))[0]\n",
    "        probability_array.append(t1c_result)\n",
    "\n",
    "        t1_result = t1_classifier.predict_proba(test_t1_data.iloc[i].to_numpy().reshape(1,-1))[0]\n",
    "        probability_array.append(t1_result)\n",
    "\n",
    "        t2_result = t2_classifier.predict_proba(test_t2_data.iloc[i].to_numpy().reshape(1,-1))[0]\n",
    "        probability_array.append(t2_result)\n",
    "\n",
    "        final_prediction = check_majority_proba(probability_array)\n",
    "\n",
    "        test_results.append(final_prediction)\n",
    "\n",
    "    test_results = np.array(test_results)\n",
    "\n",
    "    test_cases_id = test_mapping[\"ID\"].to_numpy()\n",
    "    for i in range(len(test_results)):\n",
    "        detailed_classification = detailed_classification.append({\"ID\": test_cases_id[i], \"GT\": test_labels[i], \"PRED\": test_results[i]}, ignore_index=True)\n",
    "\n",
    "    \n",
    "    clsr = classification_report(test_labels, test_results, output_dict=True)\n",
    "    print(confusion_matrix(test_labels, test_results))\n",
    "    print(classification_report(test_labels, test_results))\n",
    "\n",
    "    \n",
    "    acc = accuracy_score(test_labels, test_results)\n",
    "    kappa = cohen_kappa_score(test_labels, test_results)\n",
    "    mcc = matthews_corrcoef(test_labels, test_results)\n",
    "    precision = clsr[\"HGG\"][\"precision\"]\n",
    "    recall = clsr[\"LGG\"][\"recall\"]\n",
    "    fold_dice = float(test_mapping.Dice.mean())\n",
    "    fold_hausdorff = float(test_mapping.Hausdorff.mean())\n",
    "    fold_volume = float(test_mapping.Volume.mean())\n",
    "\n",
    "    fold_name = \"Fold_\" + str(fold_iterator)\n",
    "    fold_metrics = fold_metrics.append({\"Fold\": fold_name, \"Accuracy\": round(acc, 3), \"Kappa\": round(kappa, 3),\n",
    "                                        \"MCC\": round(mcc, 3),\"Precision\": round(precision, 3), \"Recall\": round(recall, 3),\n",
    "                                        \"Dice\": round(fold_dice, 3), \"Hausdorff\": round(fold_hausdorff, 3), \"Volume\": round(fold_volume, 3)}, ignore_index=True)\n",
    "    \n",
    "    fold_metrics.to_csv(\"fold_metrics.csv\", index=False)\n",
    "    \n",
    "    overall_acc.append(acc)\n",
    "    overall_kappa.append(kappa)\n",
    "    overall_mcc.append(mcc)\n",
    "    overall_prc.append(precision)\n",
    "    overall_rec.append(recall)\n",
    "    overall_dice.append(fold_dice)\n",
    "    overall_hausdorff.append(fold_hausdorff)\n",
    "    overall_volume.append(fold_volume)\n",
    "\n",
    "    fold_iterator += 1\n",
    "    \n",
    "detailed_classification.to_csv(\"detailed_metrics.csv\", index=False)\n",
    "general_metrics = prepare_metrics(overall_acc, overall_kappa, overall_mcc, overall_prc, overall_rec, overall_dice, overall_hausdorff, overall_volume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01f79ad-ff25-4d13-87ed-d832d60f89ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
