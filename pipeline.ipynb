{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb035585-3b7a-4db3-8f98-0fc2be8221ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score,cohen_kappa_score\n",
    "pd.options.mode.chained_assignment = None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1db5b5b8-6e5b-4bfe-82cb-bc5340aaa8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"output/features.csv\", index_col=0)\n",
    "name_mapping = pd.read_csv(\"mapping/name_mapping.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93d44a0a-675b-42d7-85dd-3e40c1b80c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_mapping_split(name_mapping):\n",
    "    labels = name_mapping.values[:,0]\n",
    "    samples = name_mapping.values[:,1]\n",
    "\n",
    "    (train_samples, test_samples, train_labels, test_labels)= sklearn.model_selection.train_test_split(samples, labels, test_size=0.2, stratify=labels)\n",
    "    \n",
    "    train_mapping = pd.DataFrame({'Grade': train_labels, 'ID': train_samples})    \n",
    "    test_mapping = pd.DataFrame({'Grade': test_labels, 'ID': test_samples})\n",
    "\n",
    "    print(\"Labels distribution:\", Counter(labels))\n",
    "    print(\"Train labels distribution:\", Counter(train_labels))\n",
    "    print(\"Test labels distribution:\",Counter(test_labels))\n",
    "    \n",
    "    return train_mapping, test_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f548fbf-1e52-43aa-a463-982d0daaacaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_data_split(raw_data, train_mapping, test_mapping):\n",
    "    train_data = pd.DataFrame(columns=raw_data.columns)\n",
    "    test_data = pd.DataFrame(columns=raw_data.columns)\n",
    "    \n",
    "    for case_id in raw_data.index:\n",
    "        case_general_id = case_id[0:20]\n",
    "        if case_general_id in train_mapping.values[:,1]:\n",
    "            train_data.loc[case_id]= raw_data.loc[case_id, :]\n",
    "        elif case_general_id in test_mapping.values[:,1]:\n",
    "            test_data.loc[case_id]= raw_data.loc[case_id, :]\n",
    "            \n",
    "    print(\"Splitting finished\")\n",
    "            \n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c4c1c0d-097b-4b89-ad94-e462d91c67a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_features(dataset):\n",
    "    X = dataset.loc[:, dataset.columns != \"Grade\"]\n",
    "    Y = dataset.loc[:, \"Grade\"]\n",
    "    \n",
    "    standard_scaler = StandardScaler().fit(X)\n",
    "    X[X.columns] = standard_scaler.fit_transform(X[X.columns])\n",
    "    \n",
    "    select_k_best = SelectKBest(f_classif).fit(X, Y)\n",
    "    \n",
    "    scored_features = pd.DataFrame({'Feature':list(X.columns), 'Score':select_k_best.scores_})\n",
    "    scored_features.sort_values(by='Score', ascending=False, inplace=True)\n",
    "    \n",
    "    best_features = scored_features.nlargest(10,'Score')\n",
    "    best_features = best_features.loc[:, \"Feature\"]\n",
    "    print(best_features)\n",
    "    best_features.to_csv(\"output/selected_features.csv\")\n",
    "\n",
    "    selected_features = X.loc[dataset.index, best_features]\n",
    "    selected_features[\"Grade\"] = Y\n",
    "    \n",
    "    return selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a203da11-d69e-43be-b5c9-04ce726ad319",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_modalities(input_data):\n",
    "    \n",
    "    flair= pd.DataFrame(columns=input_data.columns)\n",
    "    t1c = pd.DataFrame(columns=input_data.columns)\n",
    "    t1= pd.DataFrame(columns=input_data.columns)\n",
    "    t2 = pd.DataFrame(columns=input_data.columns)\n",
    "    \n",
    "    for case_id in input_data.index:\n",
    "        if \"FLAIR\" in case_id:\n",
    "            flair.loc[case_id]= input_data.loc[case_id, :]\n",
    "        elif \"T1C\" in case_id:\n",
    "            t1c.loc[case_id]= input_data.loc[case_id, :]\n",
    "        elif \"T1\" in case_id:\n",
    "            t1.loc[case_id]= input_data.loc[case_id, :]\n",
    "        elif \"T2\" in case_id:\n",
    "            t2.loc[case_id]= input_data.loc[case_id, :]\n",
    "            \n",
    "            \n",
    "    labels = (flair.loc[:, 'Grade']).to_numpy()\n",
    "    \n",
    "    flair.drop('Grade',axis='columns', inplace=True)\n",
    "    t1c.drop('Grade',axis='columns', inplace=True)\n",
    "    t1.drop('Grade',axis='columns', inplace=True)\n",
    "    t2.drop('Grade',axis='columns', inplace=True)\n",
    "    \n",
    "    print(\"Modalities splitted\")\n",
    "    \n",
    "    return flair, t1c, t1, t2, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "925f868a-8996-4ea2-ba02-a89e95c15919",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_test_dataset(dataset):\n",
    "    selected_features = pd.read_csv(\"output/best_features.csv\", index_col=0)\n",
    "    features_list = selected_features[\"Feature\"].to_list()\n",
    "    \n",
    "    X = dataset.loc[:, dataset.columns != \"Grade\"]\n",
    "    Y = dataset.loc[:, \"Grade\"]\n",
    "    \n",
    "    reduced_X = X.loc[:, features_list]\n",
    "    \n",
    "    standard_scaler = StandardScaler().fit(X)\n",
    "    reduced_X[reduced_X.columns] = standard_scaler.fit_transform(reduced_X[reduced_X.columns])\n",
    "    \n",
    "    reduced_dataset = reduced_X\n",
    "    reduced_dataset[\"Grade\"] = Y\n",
    "    \n",
    "    return reduced_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2bf0e940-dcb3-411c-ac71-eaf89708f01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkMajority(voting_arr):\n",
    "    lgg_occurences = voting_arr.count(\"LGG\")\n",
    "    hgg_occurences = voting_arr.count(\"HGG\")\n",
    "    if  hgg_occurences >= lgg_occurences:\n",
    "        return \"HGG\"\n",
    "    else:\n",
    "        return \"LGG\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e40812db-4ec7-4d2e-93f1-97ba275194ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels distribution: Counter({'HGG': 292, 'LGG': 76})\n",
      "Train labels distribution: Counter({'HGG': 233, 'LGG': 61})\n",
      "Test labels distribution: Counter({'HGG': 59, 'LGG': 15})\n"
     ]
    }
   ],
   "source": [
    "(train_mapping, test_mapping) = train_test_mapping_split(name_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e384fa3-a824-414b-964d-a4f373ef846d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting finished\n"
     ]
    }
   ],
   "source": [
    "(train_dataset, test_dataset) = train_test_data_split(dataset, train_mapping, test_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fef36dcd-ef2c-4e1e-897e-8a8690fdabdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8                         original_shape_MeshVolume\n",
      "13                       original_shape_VoxelVolume\n",
      "79            original_glrlm_RunLengthNonUniformity\n",
      "10                        original_shape_Sphericity\n",
      "57            original_gldm_DependenceNonUniformity\n",
      "2                    original_shape_LeastAxisLength\n",
      "70            original_glrlm_GrayLevelNonUniformity\n",
      "9                    original_shape_MinorAxisLength\n",
      "91    original_glszm_LargeAreaHighGrayLevelEmphasis\n",
      "60             original_gldm_GrayLevelNonUniformity\n",
      "Name: Feature, dtype: object\n"
     ]
    }
   ],
   "source": [
    "reduced_train_dataset = select_features(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44575a50-f3e3-4299-bb07-6fcf8a8a60d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modalities splitted\n"
     ]
    }
   ],
   "source": [
    "(flair_data, t1c_data, t1_data, t2_data, labels) = split_modalities(reduced_train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a331b51b-8688-4374-b877-07f0f609f326",
   "metadata": {},
   "outputs": [],
   "source": [
    "flair_classifier = RandomForestClassifier()\n",
    "t1c_classifier = RandomForestClassifier()\n",
    "t1_classifier = RandomForestClassifier()\n",
    "t2_classifier = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "52d039e7-1ed5-43ce-bded-3f5bffefab78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flair_classifier.fit(flair_data.to_numpy(), labels)\n",
    "t1c_classifier.fit(t1c_data.to_numpy(), labels)\n",
    "t1_classifier.fit(t1_data.to_numpy(), labels)\n",
    "t2_classifier.fit(t2_data.to_numpy(), labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b4d3b880-d1eb-4fb3-91c1-3b833605b0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_test_dataset = preprocess_test_dataset(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "748367fb-cde9-4f05-b42b-54fdfe1e6f0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modalities splitted\n"
     ]
    }
   ],
   "source": [
    "(test_flair_data, test_t1c_data, test_t1_data, test_t2_data, test_labels) = split_modalities(preprocessed_test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c98d9c12-6f09-40e7-b635-ab0565be9668",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_test_cases = len(test_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "225a1d54-113f-414d-aaeb-43b30e42ee8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = []\n",
    "\n",
    "for i in range(number_of_test_cases):\n",
    "        voting_arr = []\n",
    "\n",
    "        flair_result = flair_classifier.predict(test_flair_data.iloc[i].to_numpy().reshape(1,-1))[0]\n",
    "        voting_arr.append(flair_result)\n",
    "\n",
    "        t1c_result = t1c_classifier.predict(test_t1c_data.iloc[i].to_numpy().reshape(1,-1))[0]\n",
    "        voting_arr.append(t1c_result)\n",
    "\n",
    "        t1_result = t1_classifier.predict(test_t1_data.iloc[i].to_numpy().reshape(1,-1))[0]\n",
    "        voting_arr.append(t1_result)\n",
    "\n",
    "        t2_result = t2_classifier.predict(test_t2_data.iloc[i].to_numpy().reshape(1,-1))[0]\n",
    "        voting_arr.append(t2_result)\n",
    "\n",
    "        final_prediction = checkMajority(voting_arr)\n",
    "\n",
    "        test_results.append(final_prediction)\n",
    "        \n",
    "test_results = np.array(test_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "953854aa-5c27-4511-88c5-2c5770bca334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[55  4]\n",
      " [ 9  6]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         HGG       0.86      0.93      0.89        59\n",
      "         LGG       0.60      0.40      0.48        15\n",
      "\n",
      "    accuracy                           0.82        74\n",
      "   macro avg       0.73      0.67      0.69        74\n",
      "weighted avg       0.81      0.82      0.81        74\n",
      "\n",
      "Accuracy: 0.82432\n",
      "Cohen's Kappa: 0.37935\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(test_labels, test_results))\n",
    "print(classification_report(test_labels, test_results))\n",
    "\n",
    "accuracy = accuracy_score(test_labels, test_results)\n",
    "print(\"Accuracy: {:.5f}\".format(accuracy))\n",
    "print(\"Cohen's Kappa: {:.5f}\".format(cohen_kappa_score(test_labels, test_results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6672755e-50e9-4386-b1eb-e8e85906ef83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
